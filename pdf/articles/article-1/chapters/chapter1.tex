%% Начало содержательной части.
\chapter{Обзор понятий и существующих решений}

\startrelatedwork

В данный момент проблема автоматизации различных вещей, таких как поиск сообществ в социальных сетях, сильно актуальна и активно развивается. На данный момент разразботаны различные методики выделения сообществ во всем графе социальной сети \cite{Newman04, Newman06, Fortunato10, Cui13}, а также выделения плотного сообщества, содержащего все выделенные вершины в графе \cite{Faloutsos06, Wiener15, Huang15, Barbieri15}. Также были предложены методы разбиения вершин в запросе на несколько сообществ \cite{Akoglu13}~--- алгоритм DOT2DOT. Однако, почти все эти методики не поддерживают шум в запросе и выдают неоптимальные подграфы на такие запросы. Именно эту проблему мы решаем в этой работе, предложив модификации существующих алгоритмов, позволяющие эффективно выделять искомые подграфы даже если в исходном запросе существует некий шум.

\section{Термины и понятия}

В данном разделе описаны основные термины, используемые в других частях представленной работы.

\subsection{Вводные понятия теории графов}

\textbf{Декартовым произведением $A \times B$} двух множеств $A$ и $B$ называется множество всех пар $(a, b)$, таких, что $a \in A, b \in B$.

\textbf{Граф}~--- абстрактный математический объект, представляющий из себя множество \textit{вершин}, некоторые пары из которых соединены \textit{ребрами}. Здесь и далее, говоря <<\texttt{граф}>>, мы будем иметь в виду <<\texttt{неориентированный граф}>>, то есть граф, ребра которого неориентированы. Более формально, \textbf{граф} или \textbf{неориентированный граф $G$}~--- это упорядоченная пара $G := (V, E)$, где $V$~--- непустое множество вершин или узлов графа $G$, а $E$~--- множество неупорядоченных пар вершин, называемых \textit{ребрами} ($E \subset V \times V$).

Через \textbf{V(G)} будем обозначать множество вершин графа $G$, а через \textbf{E(G)} множество ребер графа $G$. Через \textbf{|V(G)|} будем обозначать количество вершин графа $G$, а через \textbf{|E(G)|} количество ребер графа $G$. Если в контексте понятно, о каком графе идет речь, будем просто писать $|V|$ и $|E|$ соответственно.

Через \textbf{$N_G(v)$} будем обозначать множество соседей вершины $v$ в графе $G$, то есть множество вершин, напрямую соединенных с $v$ ребром: $N_G(v) = \{u | (v, u) \in E(G)\}$.

\textbf{Степенью вершины} $v$ графа $G$ называется количество ребер, исходящих из этой вершины, т.е. $deg(v) = |N_G(v)|$.

\textbf{Подграфом} графа $G$ называется граф $G' := (V', E')$, такой, что $V' \subseteq V(G)$ и $E' \subseteq E(G) \cap (V' \times V')$. Иными словами, это граф, порожденный подмножеством вершин исходного графа и содержащий только ребра исходного графа $G$ между вершинами этого подмножества.

\textbf{$G[V]$} называется \textbf{порожденным подграфом} графа $G$ множеством вершин $V$, если $G[V] := (V, E[G, V])$, где $E[G, V]$~--- подмножество ребер графа $G$, оба конца которых содержатся в $V$, то есть $E[G, V] = E(G) \cap (V \times V)$.

\textbf{k-truss} графа $G$ называется максимальным по количеству вершин подграф $G' \subseteq G$, такой, что для каждого его ребра $(v, u)$ количество вершин $w$, таких, что, в $G'$ существуют ребра $(w, v)$ и $(w, u)$, не меньше $k$. Другими словами, $k-truss$~--- наибольший по размеру подграф $G'$, для каждого ребра $(v, u)$ которого $|N_{G'}(v) \cap N_{G'}(u)| >= k$.

\textbf{Простым путем} графа $G$ называется такой набор его вершин $v_1, v_2, v_3, \ldots, v_k$, что $\forall\; i, j: v_i \ne v_j$, а также $\forall\; 1 \le i \le k - 1: (v_{i-1}, v_i) \in E(G)$.

\textbf{Кратчайшим путем} из вершины $v$ в вершину $u$ называется простой путь $v_1, v_2, \ldots, v_n$ минимальной длины, то есть с минимальным $n$. Длина кратчайшего пути из $v$ в $u$ в графе $G$ обозначается как $d_G(v, u)$.

\textbf{Диаметром} графа $G$ называется длина максимального по длине кратчайшего пути в $G$. Другими словами, $diam(G) = max_{v, u \in V(G)}\; d_G(v, u)$.

\textbf{k-core} графа $G$ называется максимальный по количеству вершин подграф $G' \subseteq G$, такой, что степень каждой его вершины не меньше $k$. Для фиксированного $k$, через $C_k$ будем обозначать \textit{$k$-core}, а именно набор компонент связности, из которых он состоит. Таким образом, $C_k = \{H_i\}$, где $H_i$~--- $i$-я компонента связности, в которой степень всех вершин хотя бы $k$. Число $k$ будем называть \textbf{порядком} \textit{k-core}.

Через \boldmath$\mu(G)$\unboldmath будем обозначать минимальную степень вершин в графе $G$, т.е. $\mu(G) = \min_{v \in V(G)} deg(v)$.

\textbf{Core decomposition} или \textbf{ядерной декомпозицией} будем называть набор \textit{k-core} для всех возможных $k$: $C = \{C_k\}_{k=1}^{k=k^*}$. Стоит отметить, что из определения \textit{k-core} следует, что $C_1 \supseteq C_2 \supseteq C_3 \ldots \supseteq C_{k^*}$.

\textbf{Сore index} или \textbf{ядерным индексом} вершины $v$ будем называть минимальный по размеру \textit{k-core}, содержащий $v$, т.е. \textit{k-core} с максимальным $k$: $c(v) = \max(k \in [0..k^*] | v \in C_k)$.

\textbf{$\gamma$-quasi-clique} графа $G$ называется любой такой подграф $G' \subseteq G$, что он <<достаточно плотный>>, а именно: $\frac{2 \cdot |E(G')|}{|V(G')| \cdot (|V(G')| - 1)} \ge \gamma$.

\subsection{Социальные сети}

\textbf{Сообществом} или \textbf{Сообществом социальной сети} называется набор вершин графа социальной сети $G$, где все вершины объединяет некоторое свойство или признак. Например, <<сообщество любителей рока>> или <<сообщество акционеров Газпром>>.

\textbf{Социальной кликой} или \textbf{кликой} будем называть множество людей в социальной сети, где каждый человек знает всех остальных в этой клике, другими словами, между любой парой различных вершин в этой клике есть ребро.

\textbf{Социальной псевдокликой} или \textbf{псевдокликой} будем называть множество людей, где необязательно каждая пара различных вершин соединена ребром, однако множество людей все равно достаточно плотно связано. Оценка, насколько хорошо много связана будет зависеть от выбора типа псевдоклики и будет описана дальше в работе, однако во всех описаниях основную роль играет количество ребер в подграфе по отношению к количеству пар вершин ($\frac{2 \cdot |E(G)|}{|V(G)| \cdot (|V(G)| - 1)}$).

\textbf{Free-rider effect} называется эффект, возникающий при получении ответа на сформулированную задачу (поиск плотного сообщества по набору вершин), который содержит в себе ненужные подграфы~--- подграфы, которые можно удалить без нарушения оптимальности ответа, тем самым, уменьшив размер итогового подграфа, что является одной из первоочередных целей нашей задачи.

\subsection{Используемые сокращения}

\textbf{RW}~--- Random Walks. Идея основана на перемещении из текущей вершины в соседнюю по ребру с вероятностью, пропорциональной весу ребра.

\textbf{RWR}~--- Random Walks with Restarts. Идея аналогична идее RW, однако в этом случае также существует вероятность пойти из текущей вершины в исходную, в которой все было начато.

\textbf{Smart-ST}~--- Smart Spanning Trees. Эвристика для решения задачи Штейнера, а также используемая в статье Gionis et al. \cite{Gionis15}.

\textbf{CSP}~--- Community Search Problem. Это задача нахождения сообщества в социальной сети, содержащего все выделенные вершины.

\textbf{NCSP}~--- Noising Community Search Problem. Это задача нахождения сообщества в социальной сети, содержащего большинство выделенных вершины (то есть отсеивая шум).

\section{Обзор существующих решений}

Задача, рассматриваемая в этой статье, формулируется следующим образом: по данному графу $G$ и набору выделенных вершин $Q \subset V(G)$ требуется решить задачу поиска сообщества, содержащего большинство, но не обязательно все вершины из $Q$. Выделенные вершины из множества $Q$ мы также иногда будем называть <<вершинами-запросами>>, <<запросом>> или <<вершинами из запроса>>.

\subsection{Исходные решения}

\begin{enumerate}
  \item Задача поиска сообщества по выделенным вершинам рассматривается уже довольно давно. Еще в 2004 году Faloutsos et al. \cite{Faloutsos04} предложили алгоритм нахождения плотного сообщества по двум выделенным в графе вершинам ($|Q| = 2$). В алгоритме показывается неоптимальность метрик плотности <<кратчайший путь>> и <<максимальный поток>> между двумя заданными вершинами. Вместо этого, исходный граф представляется в виде электрической сети и используется метрика <<доставленный ток между вершинами>>~--- устанавливая напряжение \texttt{+1} на первую вершину-запрос и \texttt{0} на вторую, находится подграф, который доставляет наибольший ток между вершинами из запроса. Приведенная метрика подходит только для $|Q| = 2$, однако этот алгоритм положил начало изучению этой темы. В дальнейшем многие авторы статей оптимизировали результаты этой статьи. 

  \item Авторы второй статьи, рассмотренной для изначального изучения \cite{Faloutsos06}, предлагают функцию метрики плотности на основе \textit{random walks with restarts} (RWR), дословно переводящееся как \textit{случайные прогулки с возвращениями} (однако мы не будем использовать этот термин), используемую на взвешенном графе. Они рассматривают $r(i,j)$~--- вероятность того, что начав в $i$-й вершине-запросе $q_i$, с помощью RWR, где на каждом шаге из текущей вершины мы переходим в соседнюю по ребру с вероятностью пропорциональной весу ребра, мы закончим в вершине $j$. Также вводится $r(Q, j)$, равная сумме $r(i, j)$ для всех вершин-запросов: $r(Q, j) = \sum_{i = 1}^{i = |Q|}\; r(i, j)$. Метрика плотности вводится как $g(H) = \sum_{j \in H}\; r(Q, j)$. Этот метод показал достаточно хорошие результаты по сравнению со статьей 2004 года, так как расширил возможность поиска подграфа с $|Q| = 2$ до $2 \le |Q| \le |V(G)|$, а также ввел возможность поиска подграфа, содержащего не все вершины, а только хотя бы $k$ из них ($k$~--- параметр, данный на входе). Это операция была названа $K\_softAND$ и была успешно реализована в статье. Последующие алгоритмы развивали эту тему, применяли другие метрики и улучшили результаты этого алгоритма, однако задача поиска подграфа, содержащего не обязательно все, а только часть вершин-запросов в ответе, больше практически не поднималась, улучшения операции $K\_softAND$ не рассматривались ввиду количества других возможных применений и улучшений поставленной задачи. 

  \item Авторы третьей статьи, рассмотренной для изначального изучения \cite{Wiener15}, предлагают в качестве метрики плотности брать \textit{индекс Винера}~--- попарную сумму кратчайших расстояний между вершинами из запроса. Авторы статьи пытаются решить проблему большого графа в результате обрабатывания запроса, если вершины-запросы находятся в нескольких сообществах и слабо связаны между собой. Для решения этой проблемы авторы предлагают добавлять в запрос несколько <<важных вершин>>, который будут связывать сообщества, пусть и не очень плотно. Результаты показали, что этот метод работает в несколько раз лучше большинства предыдущих \cite{Faloutsos06, Sozio10} и примерно так же, как методы, основанные на \textit{проблеме Штейнера}. Однако в статье не рассмотрены более поздние методы на основе \textit{проблемы Штейнера}, которые заметно улучшили результаты предыдущих, что делает этот метод менее приоритетным по сравнению с ними.
\end{enumerate}

\subsection{Нахождение оптимальных псевдоклик}

Больш\'{у}ю часть всех алгоритмов для решения описанной задачи занимают алгоритмы, основанные на нахождении оптимальных псевдоклик с некоторыми дополнительными эвристиками. Рассмотренных в алгоритмах псевдоклик довольно много: например, \textit{k-core} \cite{Barbieri15}, \textit{k-truss} \cite{Huang15}, \textit{$\gamma$-quasi-clique} \cite{Zhu11} или просто алгоритмы, максимизирующие плотность ребер в полученном подграфе \cite{Wu15}, что, фактически, и является определением псевдоклики. Для каждой из этой псевдоклик алгоритмы развиваются, улучшают полученные результаты, используя новые эвристики. Сравнивать результаты алгоритмов, использующих разные псевдоклики, довольно сложно и вряд ли даст видимые результаты, потому что из-за разницы оптимизируемых функций полученные результаты сильно зависят от исходных графов и запросов. В некоторых случаях определенные псевдоклики будут давать результаты лучше других, в некоторых~--- хуже, поэтому имеет смысл сравнивать только средние показатели результатов, однако это тоже не дает полного понимания оптимальности или неоптимальности алгоритмов.

Рассмотрим несколько последних алгоритмов для наиболее популярных псевдоклик:

\begin{enumerate}
  \item X. Huang et al. \cite{Huang15} в качестве псевдоклик выбирают \textit{k-truss}. Однако, просто нахождение оптимального \textit{k-truss} (то есть \textit{k-truss}, содержащий в себе все вершины-запросы, с максимальным $k$)~--- не оптимально, а также это уже решенная за полиномимальное время задача. Поэтому авторы статьи предлагают находить \textit{k-truss} с максимальным $k$ и минимальным диаметром, что, как они показывают в своей статье, уже NP-полная задача. Однако, эта идея должна показывать хорошие результаты, поэтому авторами была проведено исследование в попытке понять, насколько близкий ответ можно получить за полиномиальное время. Оказалось, что задачу нельзя решить с точностью лучше, чем в $(2 - \varepsilon)$ раз хуже для любого $\varepsilon > 0$ (под точностью подразумевается длина диаметра в полученном ответе). Однако, авторами был предложен эвристический алгоритм, который в худшем случае делает ошибку ровно в $2$ раза, что показывает, что он является оптимальным для решения поставленной авторами задачи. Алгоритм основывается на построении предполагаемого максимального \textit{k-truss} с последующий итеративным удалением вершин, не ухудшающих ответ и уменьшающих длину диаметра. Результаты, полученные в статье также являются довольно неплохими по сравнению с предыдущими статьями \cite{Sozio10, Wu15}, однако, даже несмотря на то, что в статье доказана полная оптимальность разработанного алгоритма, оптимальным для решения всей задачи (нахождения плотного подмножества по заданному множеству вершин) он не является, поскольку авторами был разработан алгоритм только для поставленной \textit{ими} задачи. 

  \item N. Barbieri et al. \cite{Barbieri15} в качестве псевдоклик выбирают \textit{k-core}. Однако, и здесь простое нахождение оптимального \textit{k-core} (то есть \textit{k-core}, содержащий в себе все вершины-запросы, с максимальным $k$)~--- не оптимально, а также уже решено за полиномиальное время \cite{Sozio10}. Поэтому авторы статьи применяют эвристики, нацеленные на минимизацию размера итогового подграфа с сохранением его оптимальности. Эти эвристики позволяют свести задачу к поиску ответа в компоненте связности $H^* \subset G$, причем при этом гарантируется, что все возможные оптимальные ответы на исходную задачу лежат в $H^*$. После этого авторы статьи приводят несколько эвристик для минимизации полученного подграфа $H^*$, содержащего все решения задачи. Само утверждение, описанное авторами, не ново, однако выглядит интересным для дальнейших исследований, потому что добавляет в постановку задачи больше информации без потери решений. Результаты статьи показывают, что метод действительно работает лучше и быстрее предыдущих \cite{Sozio10, Cui14}, причем результаты улучшены примерно так же хорошо, как и у X. Huang et al. \cite{Huang15}. Исходя из информации, описанной выше, было сделано решение выбрать эту статью как основу для улучшений и расширений на нашу постановку задачи.

  \item Y. Wu et al. \cite{Wu15} в качестве псевдоклик выбирают \textit{query-biased} плотность ребер, основанную на \textit{RW}. Авторы нацелены на устранение \textit{free-rider effect}, который проявляется во многих имеющихся алгоритмах, поэтому формулируют новую задачу поиска подграфа, содержащего все вершины-запросы с максимальной \textit{query-biased} плотностью. Результаты статьи показывают, что метод действительно оптимизует существующие решения и практически не проявляет в себе \textit{free-rider effect}. Он показал результаты лучше существовавших на тот момент \textit{k-core} решений \cite{Sozio10}, \textit{$\gamma$-quasi-clique} решений \cite{Zhu11}, а также некоторых других решений. Однако, новые решения \cite{Huang15, Barbieri15} также практически лишены \textit{free-rider effect}, поэтому по сравнению с ними этот алгоритм будет не оптимальнее.
\end{enumerate}

\subsection{Другие методики}

Как уже было рассмотрено ранее, оптимизируемые функции бывают довольно разные. В предыдущей части были рассмотрены псевдоклики, здесь мы рассмотрим несколько других популярных оптимизируемых функций.

\begin{enumerate}
  \item L. Akoglu et al. \cite{Akoglu13} немного меняют постановку задачи, пытаясь найти подграф, объединяющий не все вершины в запросе, а различные их группы. То есть идея фактически состоит в разбиении запроса на группы и построения ответа для каждой группы отдельно, чтобы в каждой группе вершины были плотно связаны и объединены каким-то общим свойством, а между собой группы были связаны не очень сильно. Это соответствует разбиению запроса на несколько сообществ. Результаты статьи показали, что этот метод довольно неплохо решает поставленную в статье задачу, однако, как уже было сказано выше, эта задача отличается от нашей и сравниваться с ней довольно сложно. Ее можно свести к нашей задаче, однако это сведение не равносильное и требует дополнительного исследования.

  \item A. Gionis et al. \cite{Gionis15} в своей статье рассматривают метрику \textit{линейное локальное несоответствие} (она же \textit{linear local discrepancy}), которая равна взвешенной разнице количества вершин-запросов в итоговом подграфе-ответе и количества остальных вершин. Более точно, $g(C) = \alpha p_C - n_C$, где $p_C = |Q \cap V(C)|$, а $n_C = |V(C) \setminus Q|$. Алгоритм, максимизирующий эту функцию, основан на \textit{проблеме Штейнера}, описанной ранее, а также \textit{<<Умных>> минимальных остовных деревьяв} (они же \textit{Smart-ST}). Отличительной чертой этого алгоритма является возможность решать задачу, используя \textit{локальную модель доступа}, то есть модель, где весь граф изначально неизвестен (или он слишком большой, чтобы его полностью и быстро сохранить в оперативную память или на диск), и API позволяет только делать запросы на получение всех соседей вершины~--- $get-neighbours$. Эта модель позволяет решать задачу оптимально даже на очень больших графах социальных сетей, таких как \textit{Twitter}, \textit{Facebook}, а также многих других. Исходя из постановки задачи, в итоговом найденном подграфе вполне могут содержаться не все вершины, что совпадает с темой нашего исследования, однако метрика не очень подходит именно к нашей задаче~--- в ней не учитывается реберная плотность полученного подграфа, а учитывается только соотношение количества вершин. Также в ответ вполне может войти довольно мало вершин из исходного запроса, нас такое тоже не устраивает.
\end{enumerate}

\section{Уточненные требования к работе}

Подведем итог описанного выше обзора имеющихся решений. Большинство текущих рещений достаточно оптимально решают CSP~--- каждый использует свою метрику, но получает достаточно хорошие результаты. Однако, как мы можем заметить, что решение NCSP, то есть учитывание <<шума>>, почти не поднимается в текущих решениях. Мы отметили рассмотрение задачи NCSP в статьях C. Faloutsos \& H. Tong \cite{Faloutsos06}, а также A. Gionis et al. \cite{Gionis15}, однако там эта задача не является основной и цель сфокусировать результаты на этом не является первоочередной. Соответственно, целью нашей статьи будет разработка алгоритма, фокусирующегося на поиске плотного подграфа, не содержащего в себе исходной шум в запросе. Требования к нему будут следующие:
\begin{enumerate}
  \item Алгоритм должен показывать результаты лучше текущих имеющихся решений \cite{Faloutsos06, Gionis15, Barbieri15};
  \item Алгоритм должен быть достаточно оптимальным, желательно не проигрывающим по времени работы текущим аналогам;
  \item Плюсом будет поддержка обратной совместимости~--- есть пользователь захочет все-таки найти подграф, содержащий все вершины в запросе, это должно быть возможно;
\end{enumerate}

\finishrelatedwork

\chapterconclusion

В главе были описаны основные определения, требуемые для понимания статьи и ее терминов, а также приведен обзор текущих решений поставленной задачи. Обзор показал, что за $13$ лет было изучено множество подходов к решению CSP, однако изучаемая в этой бакалаврской работе NCSP изучена не очень хорошо, поэтому ее усовершенствование более чем резонно. 

В конце главы были приведены новые требования к работе, мотивирующие и показывающие возможность создания алгоритма, работающего лучше предыдущих исследований.